{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erste Datenübersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Link to github repo:\n",
    "\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "'''\n",
    "%load_ext lab_black\n",
    "%matplotlib inline\n",
    "'''\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from data_io import File_IO, Database_IO\n",
    "from data_wrangling import  Data_Wrangling\n",
    "from data_summarization import Data_Summarization\n",
    "from setup_config import Setup_Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "setup = Setup_Config('config.ini') # loads a setup file with variables in .ini format\n",
    "# the .ini file contains e.g. database connections and other settings.\n",
    "#### ATTENTION: make sure to add this file to successfully to .gitignore to make sure it dont become pushed to the public repo.\n",
    "\n",
    "file_io = File_IO() # handles input and output operations\n",
    "\n",
    "data_wrangling = Data_Wrangling(data_io=file_io) # includes all the transformations\n",
    "data_summarizations = Data_Summarization(data_io=file_io)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuelle Analyse\n",
    "\n",
    "### Auffälligkeiten\n",
    "\n",
    "\n",
    "In dem Datensatz ist für jeden Patienten ein Ordner angelegt.\n",
    "Jeder Patientenordner beeinhaltet einen Ordner für die unterschiedlichen Upload-Arten.\n",
    "Zu jeder Upload-Art sind in dem Ordner die einzellnen Upload zu finden, z.B. als zip-Files, aber auch Excel-Files, andere Format sind möglich.\n",
    "\n",
    "Bsp.:\n",
    "Patient 73295423 enthält die Upload-Art direct-sharing-133 und darutern eine xslx Datei mit einem Suggermate-Report.\n",
    "\n",
    "\n",
    "- Frage 1: Welche Upload Arten gibt es ?\n",
    "- Frage 2: Welche Datentypen und Struktur ist dort erkennbar?\n",
    "\n",
    "- Ziel: Überführung in eine einheitliche Datenstruktur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "path = '/Users/me/Desktop/Code/VS-Projects/charite/OpenHumansDataTools/data/raw/n=101_OPENonOH_07.07.2022'\n",
    "folder_structure = pd.DataFrame(file_io.get_folder_structure(path))\n",
    "folder_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "lv1_unique = list(folder_structure.level_1.unique())\n",
    "lv1_unique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zu Frage 1:\n",
    "\n",
    "Es gibt drei verschiedene Ordnerarten für die Uploads:\n",
    "- direct-sharing-31\n",
    "- direct-sharing-396\n",
    "- direct-sharing-133"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erste Analyse von `direct-sharing-31`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "file_names_lv1 = list(folder_structure[folder_structure['level_1'] == lv1_unique[0]]['file'])\n",
    "file_names_lv1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manuelle Betrachtung von `direct-sharing-31`:\n",
    "\n",
    "Enthalten sind mit gz komprimierte json-files. \n",
    "Der Filename besteht jeweils aus einem dem Inhalt entsprechenden Text-Identifier, optional gefolgt von einer Zeitspanne. Ein Beispiel Filename sieht so aus:\n",
    "\n",
    "`profile_2018-06-01_to_2018-06-26.json.gz`\n",
    "\n",
    "Alternativ kann auch das Startdatum fehlen, z.B. bei:\n",
    "\n",
    "`treatments__to_2017-10-13.json.gz`\n",
    "\n",
    "oder gar keine Datumsrange angegeben sein, z.B. bei:\n",
    "\n",
    "`profile.json.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Frage 1.2. Welche Filenamen können auftreten?\n",
    "all_names = []\n",
    "for file_name in file_names_lv1:\n",
    "    name = file_name.split('.')[0] # Endungen ignorieren\n",
    "    name = name.split('_')[0] # if date ranges are specified, we parse them out\n",
    "    all_names.append(name)\n",
    "\n",
    "unique_file_typs = list(set(all_names))\n",
    "unique_file_typs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt 4 verschiedene Arten von Files in `direct-sharing-31`:\n",
    "\n",
    "- profile\n",
    "- treatments\n",
    "- devicestatus\n",
    "- entries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erste Analyse von `direct-sharing-396`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "file_names_lv1 = list(folder_structure[folder_structure['level_1'] == lv1_unique[1]]['file'])\n",
    "#print(lv1_unique[1])\n",
    "for name in file_names_lv1: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "lv1 = folder_structure[folder_structure['level_1'] == lv1_unique[1]]\n",
    "#lv1[~lv1['file'].str.contains('upload')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manulle Analyse:**\n",
    "\n",
    "Zip folder in der Struktur:\n",
    "- upload-num82-ver1-date20201220T122408-appid6aa9e9a384264323b3c82447483b92bb.zip\n",
    "\n",
    "Zusätzlich können auch JSON-Files enthalten sein. Die JSON-Files sind nur vorhanden, da einige Zip-Folder vorab schon manuell entpackt wurden.\n",
    "Es reicht die Betrachtung der einzellnen upload-zip-Folder.\n",
    "\n",
    "- TemporaryTargets.json\n",
    "- Carbs.json\n",
    "- UploadInfo.json\n",
    "- VersionChanges.json\n",
    "- BgReadings.json\n",
    "- Preferences.json\n",
    "- DisplayInfo.json\n",
    "- TemporaryBasals.json\n",
    "- DeviceInfo.json\n",
    "- BolusCalculatorResults.json\n",
    "- Boluses.json\n",
    "- GlucoseValues.json\n",
    "- TherapyEvents.json\n",
    "- ApplicationInfo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "different_filenames = []\n",
    "\n",
    "for name in file_names_lv1:\n",
    "\n",
    "    upload_name_info = name.split('-')\n",
    "    if not len(upload_name_info) == 5: # get exceptions from the usual structure\n",
    "        different_filenames.append(name)\n",
    "\n",
    "\n",
    "list(set(different_filenames)) # unique and different filenames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevante Frage: Was ist den upload zip-Files enthalten?\n",
    "\n",
    "Entpacken und betrachten aller Files auf Grund von lokalen Speicherbegrenzeungen nicht möglich. Vermutung (überprüft mit Stichproben): verschiedene JSON-Files, welche die Daten entahlten."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erste Analyse von `direct-sharing-133`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "s133_file_names_lv1 = list(folder_structure[folder_structure['level_1'] == lv1_unique[2]]['file'])\n",
    "#print(lv1_unique[2])\n",
    "for name in s133_file_names_lv1: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "folder_structure[folder_structure['file'].isin(s133_file_names_lv1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuelle Analyse\n",
    "\n",
    "`direct-sharing-133` wird nur bei zwei Patienten verwenden. Daten sind bei einem Patienten mit Diagrammen als Analyse in einer Exceldatei zusammengefasst, die automatisch generiert wurde.\n",
    "Die Daten in dem `nightscout-db.zip` file sind noch unklar und werden vorerst nicht betrachtet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuelle Analyse von Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "folder_structure[~folder_structure['level_2'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Level 2 sind nur Folder enthalten, welche vermutlich zur exploaration vor dem Upload in Google Drive versehentlich entpackt wurden. Hierbei handelt es sich um in ursprünglich in Level 1 direct-sharing-396 komprimierte upload Ordner der Stuktur s.o..\n",
    "\n",
    "Level 2 ist somit vorerst nicht relevant und wird im folgenden ignoriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "folder_structure.level_2.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konzeptentwicklung für das Preprocessing (Normalisieren und Sammlen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Was soll Preprocessed werden ?\n",
    "\n",
    "Es werden in jedem Patientenordner, falls vorhanden, die folgenden Unterordner aufbereitet:\n",
    "- direct-sharing-31 (ds31)\n",
    "- direct-sharing-396 (ds396)\n",
    "\n",
    "In ds31 können bis zu 4 verschieden JSON-Files vorkommen, im Namen wird ggf. mit _ getrennt eine Zeitintervall für die erhobenen Daten, ggf. auch offen, angegeben.\n",
    "\n",
    "In ds396 werden nur die mit upload_ bezeichneten zip Folder betrachtet und zunächst davon ausgegangen, dass die relevanten Daten in json kodierten Files vorhanden sind. Alle vorkommenden JSON Files sollen vorverarbeitet werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wie wird das umgesetzt ?\n",
    "\n",
    "Für jeden Patienten soll final eine csv-Datei entstehen, in welcher sämtliche Daten aus ds31 und ds396 übersichtlich gespeichert werden. Alle csv Datein sollen zusätzlicher in einer Datnbanktabelle gespeichert werden.\n",
    "\n",
    "Um die jeweiligen JSON-Datein in eine csv-Datei zu integrieren soll die verschachtelte Struktur der Datein aufgelöst werden, sodass diese durch Pfade der folgende Art x.y.z... ersetzt werden.\n",
    "Die Pfade werden in lowercase kodiert.\n",
    "Zuerst enthält der Pfad die Upload-Art, z.B. ds31. Anschließend folgt mit y der Filename und z die punktierte Auflistung des verschatelten Pfades in der JSON Datei entland den keys des dicts bis zum aktuellen Variablen Namen.\n",
    "\n",
    "Die Ziel CSV-Datei soll die folgende Struktur enthalten: \n",
    "\n",
    "| patient_id         | path      | #upload| value | value_str | starttime | duration | isValid | \n",
    "|-------------------|------------|----|--|-------------|--------|---------|------------|\n",
    "| 59061279 | ds31.profile.defaultprofile   | |    | Default   | 2019-07-14 05:20:22 | None |False   | \n",
    "| 59061279| ds396.profile.value1     | |2.0   |           | 2019-07-14 05:20:22 | None |True   | \n",
    "\n",
    "\n",
    "Hierdurch wird die agile Möglichkeit gegeben numerische Daten in `value` festzuhalten, alternativ textuelle Daten in `value_str`. Erste Einblicke haben gezeigt, dass einige mit Zeit angegebene Werte auch eine `duration` beeinahlten, ggf. muss diese berechnet werden.\n",
    "Wenn Parameter die Gültigkeit einer Messung spezifizieren, wird diese zusätzlich mit angegeben.\n",
    "Die #upload (Upload Number) gibt an, der wievielte Upload die Information enthält.\n",
    "Die Struktur der csv-Datei ermöglicht das einfache filtern der Daten.\n",
    "\n",
    "Zusätzlich wird eine Datenbank auf einem Server aufgesetzt und die finalen csv-Datein werden in eine geeignete Datenbank-Tabelle eingelesen. Für die Tabelle wird ein Index erstellt und ggf. die Datenbank Performance optimiert.\n",
    "Erwartet wird eine Datengröße von bis zu 5GB pro Patient. Die Gesammtgröße von möglicheriweise > 500GB für nur 100 Patienten ist somit für Researcher schwer ohne entsprechende Infrastruktur zu managen .\n",
    "\n",
    "Durch eine Materialized-View soll ein Überblick zu möglichen Pfaden, sowie trivialen Statistiken (wie mean, min, max) für die numerischen Variablen erfolgen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welche Risiken gibt es bei der Umsetzung ?\n",
    "\n",
    "- Es muss mit unterschiedlichen Zeitzonen gerechnet werden und die zugehörige Zeitzoneninformation in den Daten erkannt werden.\n",
    "\n",
    "- Die Werte sind ggf. nicht mit Identifier-Value oder zeitlicher Notierung starttime angegeben.\n",
    "Hier müssen mögliche Bezeichnungen gefiltert und normalisiert werden.\n",
    "\n",
    "- Erste Einblicke haben gezeigt, dass tw. auch ein startdate und timeasseconds in Unix-Miliseconds-Time angegeben ist. Hieraus kann dann eine starttime berechnet werden.\n",
    "\n",
    "Weitere Risiken sind denkbar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erweitertes Preprocessing\n",
    "\n",
    "Ärzten und weitere Wissenschaftlern wird die Variablenübersicht zur Verfügung gestellt.\n",
    "Auf Anfrage können dann aus relevanten Variablen speziell strukturierte Materialized-Views mit Zieldaten erstellt werden.\n",
    "\n",
    "Denkbar sind auch weitere Aufbereitungen, wie Data-Cleaning (z.B. Outlier Filtern), Datenaggregation und Umstrukturierung."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csp",
   "language": "python",
   "name": "csp"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
